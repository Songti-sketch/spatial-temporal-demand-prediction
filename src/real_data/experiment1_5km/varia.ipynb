{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from preprocessing3 import Preprocessor\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# why time average estimation performs well? \n",
    "- because every day aggregate amount of orders stays stable, that is to say, low variances. Thus, we want to see the variance distribution of grids, and look for the boundary of time-average method, i.e, when will time-average method fails, i.e, variance become too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing grid size: 0.6 kmProcessing grid size: 0.2 kmProcessing grid size: 1.0 kmProcessing grid size: 0.8 kmProcessing grid size: 0.4 kmProcessing grid size: 0.5 kmProcessing grid size: 0.3 kmProcessing grid size: 0.1 kmProcessing grid size: 0.7 kmProcessing grid size: 0.9 kmProcessing grid size: 5.0 kmProcessing grid size: 1.5 kmProcessing grid size: 4.0 km\n",
      "Processing grid size: 3.0 km\n",
      "\n",
      "Processing grid size: 2.0 km\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing grid size: 2.5 km\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "data_path = '/home/go3/wch_code/jx/real_data/data/cleaned_data2.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define the dates\n",
    "all_dates = ['2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21']\n",
    "all_dates = [pd.to_datetime(date).date() for date in all_dates]\n",
    "\n",
    "# Preprocess the data\n",
    "df = Preprocessor.preprocess(df, all_dates)\n",
    "\n",
    "# Define time windows (hourly from 08:00 to 23:59)\n",
    "time_windows = [\n",
    "        ('08:00', '09:59:59'), \n",
    "        ('10:00', '11:59:59'), \n",
    "        ('12:00', '13:59:59'),\n",
    "        ('14:00', '15:59:59'), \n",
    "        ('16:00', '17:59:59'), \n",
    "        ('18:00', '19:59:59'),\n",
    "        ('20:00', '21:59:59'), \n",
    "        ('22:00', '23:59:59')\n",
    "    # ('08:00:00', '08:59:59'),\n",
    "    # ('09:00:00', '09:59:59'),\n",
    "    # ('10:00:00', '10:59:59'),\n",
    "    # ('11:00:00', '11:59:59'),\n",
    "    # ('12:00:00', '12:59:59'),\n",
    "    # ('13:00:00', '13:59:59'),\n",
    "    # ('14:00:00', '14:59:59'),\n",
    "    # ('15:00:00', '15:59:59'),\n",
    "    # ('16:00:00', '16:59:59'),\n",
    "    # ('17:00:00', '17:59:59'),\n",
    "    # ('18:00:00', '18:59:59'),\n",
    "    # ('19:00:00', '19:59:59'),\n",
    "    # ('20:00:00', '20:59:59'),\n",
    "    # ('21:00:00', '21:59:59'),\n",
    "    # ('22:00:00', '22:59:59'),\n",
    "    # ('23:00:00', '23:59:59')\n",
    "]\n",
    "\n",
    "# Define grid sizes in kilometers\n",
    "dist_per_grid_list = [\n",
    "    0.1, 0.2,\n",
    "    0.3, 0.4,\n",
    "    0.5, \n",
    "    0.6, 0.7,\n",
    "    0.8, 0.9, \n",
    "    1.0, 1.5, 2.0, \n",
    "    2.5, 3.0, \n",
    "    4.0, \n",
    "    5.0\n",
    "    ]\n",
    "\n",
    "# Process each grid size\n",
    "# for dist_per_grid in dist_per_grid_list:\n",
    "\n",
    "def run_single_combination(args):\n",
    "    dist_per_grid= args\n",
    "    # Print the current grid size being processed\n",
    "    print(f\"Processing grid size: {dist_per_grid} km\")\n",
    "    \n",
    "    # Assign grid indices based on sender location\n",
    "    base_df, num_total_cells, _, _, _, _, _ = Preprocessor.cut_df(df, dist_per_grid, timeperiod=60)\n",
    "    \n",
    "    # Dictionary to store variances for each time window\n",
    "    variance_data = {}\n",
    "    mean_var = {}\n",
    "    # Process each time window\n",
    "    for tw in time_windows:\n",
    "        start_time = pd.to_datetime(tw[0]).time()\n",
    "        end_time = pd.to_datetime(tw[1]).time()\n",
    "        \n",
    "        # Filter orders within the time window\n",
    "        tw_df = base_df[(base_df['time'] >= start_time) & (base_df['time'] <= end_time)]\n",
    "        \n",
    "        # Count orders per grid cell per day\n",
    "        counts = tw_df.groupby(['sell_index', 'date']).size().reset_index(name='count')\n",
    "        \n",
    "        # Calculate variance of order counts across days for each grid cell\n",
    "        variances = counts.groupby('sell_index')['count'].var().reset_index(name='variance')\n",
    "        \n",
    "        # Store variances, excluding NaN (grid cells with orders on only one day)\n",
    "        variance_data[tw] = variances['variance'].dropna().values\n",
    "\n",
    "        # drop out outliers\n",
    "        if len(variance_data[tw]) > 0:\n",
    "            q1 = np.percentile(variance_data[tw], 25)\n",
    "            q3 = np.percentile(variance_data[tw], 75)\n",
    "            q95 = np.percentile(variance_data[tw], 95)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            upper_bound = min(upper_bound, q95)  # cap the upper bound at the 95th percentile\n",
    "            # variance_data[tw] = variance_data[tw][(variance_data[tw] >= lower_bound) & (variance_data[tw] <= upper_bound)]\n",
    "            variance_data[tw] = variance_data[tw][(variance_data[tw] <= upper_bound)]\n",
    "\n",
    "        mean_var[tw] = variances['variance'].mean()\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    for tw in time_windows:\n",
    "        variances = variance_data[tw]\n",
    "        for var in variances:\n",
    "            plot_data.append({'time_window': f\"{tw[0]}-{tw[1]}\", 'variance': var})\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    save_path = 'var_boxplot'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Create and save the boxplot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    lab_size = 15\n",
    "    font_size = 15\n",
    "    sns.boxplot(x='time_window', y='variance', data=plot_df)\n",
    "    # for idx, time_window in enumerate(plot_df.columns):\n",
    "    #         mean_val = mean_var[time_window]\n",
    "    #         if not np.isnan(mean_val):\n",
    "    #             plt.plot(idx, mean_val, 'rD', markersize=8, label='Mean' if idx == 0 else '')\n",
    "    # for each time window, plot the mean variance\n",
    "    for idx, tw in enumerate(time_windows):\n",
    "        mean_val = mean_var[tw]\n",
    "        if not np.isnan(mean_val):\n",
    "            plt.plot(idx, mean_val, 'rD', markersize=8, label='Mean' if idx == 0 else '')\n",
    "    plt.title(f'Variance of Order Counts Across Days for Grid Size {dist_per_grid} km', fontsize=15)\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.tick_params(labelsize=lab_size)\n",
    "    ax.set_xlabel(\"Time Window'\",fontsize=font_size)\n",
    "    ax.set_ylabel(\"Variance\",fontsize=font_size)\n",
    "    # plt.xlabel('Time Window', fontsize=15)\n",
    "    # plt.ylabel('Variance', fontdict=15)\n",
    "    plt.xticks(rotation=45)\n",
    "    sns.set(font_scale=1) # set the font scale for seaborn\n",
    "    sns.set(style='white')  # \n",
    "    sns.despine() # means removing the top and right spines\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/variance_boxplot_dpg_{dist_per_grid}.png')\n",
    "    plt.close()\n",
    "\n",
    "# print(\"Processing complete. Boxplot figures have been saved.\")\n",
    "\n",
    "# make the whole process parallel\n",
    "import multiprocessing\n",
    "max_processors = multiprocessing.cpu_count() - 1  # Leave one processor free\n",
    "combinations = [(dpg) for dpg in dist_per_grid_list]\n",
    "with multiprocessing.Pool(processes=max_processors) as pool:\n",
    "    args_list = [(dpg) \n",
    "                for dpg in combinations]\n",
    "    results_list = pool.map(run_single_combination, args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing grid size: 0.2 kmProcessing grid size: 0.5 kmProcessing grid size: 0.3 kmProcessing grid size: 0.1 kmProcessing grid size: 0.4 km\n",
      "Processing grid size: 0.6 kmProcessing grid size: 0.9 kmProcessing grid size: 0.7 kmProcessing grid size: 2.0 kmProcessing grid size: 0.8 km\n",
      "Processing grid size: 1.0 km\n",
      "Processing grid size: 1.3 km\n",
      "Processing grid size: 2.5 km\n",
      "Processing grid size: 3.0 kmProcessing grid size: 1.5 kmProcessing grid size: 3.8 kmProcessing grid size: 3.3 km\n",
      "Processing grid size: 4.5 km\n",
      "\n",
      "Processing grid size: 2.8 kmProcessing grid size: 1.8 km\n",
      "Processing grid size: 2.3 kmProcessing grid size: 3.5 km\n",
      "\n",
      "Processing grid size: 4.3 kmProcessing grid size: 4.0 km\n",
      "\n",
      "Processing grid size: 5.0 kmProcessing grid size: 4.8 km\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing complete. All plots have been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import multiprocessing\n",
    "# from Preprocessor import Preprocessor  # Assuming this is defined elsewhere\n",
    "\n",
    "# Load the data\n",
    "data_path = '/home/go3/wch_code/jx/real_data/data/cleaned_data2.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define the dates\n",
    "all_dates = ['2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21']\n",
    "all_dates = [pd.to_datetime(date).date() for date in all_dates]\n",
    "\n",
    "# Preprocess the data\n",
    "df = Preprocessor.preprocess(df, all_dates)\n",
    "\n",
    "# Define time windows (hourly from 08:00 to 23:59)\n",
    "time_windows = [\n",
    "    ('08:00', '09:59:59'), \n",
    "    ('10:00', '11:59:59'), \n",
    "    ('12:00', '13:59:59'),\n",
    "    ('14:00', '15:59:59'), \n",
    "    ('16:00', '17:59:59'), \n",
    "    ('18:00', '19:59:59'),\n",
    "    ('20:00', '21:59:59'), \n",
    "    ('22:00', '23:59:59')\n",
    "]\n",
    "\n",
    "# Define grid sizes in kilometers\n",
    "dist_per_grid_list = [\n",
    "    0.1, 0.2, 0.3, 0.4, 0.5, \n",
    "    0.6, 0.7, 0.8, 0.9, 1.0, \n",
    "    1.3, 1.5, 1.8,\n",
    "    2.0, 2.3, 2.5, 2.8, \n",
    "    3.0, 3.3, 3.5, 3.8, \n",
    "    4.0, 4.3, 4.5, 4.8, 5.0\n",
    "]\n",
    "\n",
    "def run_single_combination(dist_per_grid):\n",
    "    # Print the current grid size being processed\n",
    "    print(f\"Processing grid size: {dist_per_grid} km\")\n",
    "    \n",
    "    # Assign grid indices based on sender location\n",
    "    base_df, num_total_cells, _, _, _, _, _ = Preprocessor.cut_df(df, dist_per_grid, timeperiod=60)\n",
    "    \n",
    "    # Dictionary to store variances for each time window\n",
    "    variance_data = {}\n",
    "    mean_var = {}\n",
    "    # Process each time window\n",
    "    for tw in time_windows:\n",
    "        start_time = pd.to_datetime(tw[0]).time()\n",
    "        end_time = pd.to_datetime(tw[1]).time()\n",
    "        \n",
    "        # Filter orders within the time window\n",
    "        tw_df = base_df[(base_df['time'] >= start_time) & (base_df['time'] <= end_time)]\n",
    "        \n",
    "        # Count orders per grid cell per day\n",
    "        counts = tw_df.groupby(['sell_index', 'date']).size().reset_index(name='count')\n",
    "        \n",
    "        # Calculate variance of order counts across days for each grid cell\n",
    "        variances = counts.groupby('sell_index')['count'].var().reset_index(name='variance')\n",
    "        \n",
    "        # Store variances, excluding NaN\n",
    "        variance_data[tw] = variances['variance'].dropna().values\n",
    "\n",
    "        # Remove outliers\n",
    "        if len(variance_data[tw]) > 0:\n",
    "            q1 = np.percentile(variance_data[tw], 25)\n",
    "            q3 = np.percentile(variance_data[tw], 75)\n",
    "            q95 = np.percentile(variance_data[tw], 95)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            upper_bound = min(upper_bound, q95)\n",
    "            variance_data[tw] = variance_data[tw][(variance_data[tw] <= upper_bound)]\n",
    "\n",
    "        mean_var[tw] = variances['variance'].mean()\n",
    "\n",
    "    # Prepare data for boxplot\n",
    "    plot_data = []\n",
    "    for tw in time_windows:\n",
    "        variances = variance_data[tw]\n",
    "        for var in variances:\n",
    "            plot_data.append({'time_window': f\"{tw[0]}-{tw[1]}\", 'variance': var})\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    save_path = 'var_boxplot'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Create and save the boxplot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    lab_size = 15\n",
    "    font_size = 15\n",
    "    sns.boxplot(x='time_window', y='variance', data=plot_df)\n",
    "    for idx, tw in enumerate(time_windows):\n",
    "        mean_val = mean_var[tw]\n",
    "        if not np.isnan(mean_val):\n",
    "            plt.plot(idx, mean_val, 'rD', markersize=8, label='Mean' if idx == 0 else '')\n",
    "    plt.title(f'Variance of Order Counts Across Days for Grid Size {dist_per_grid} km', fontsize=15)\n",
    "    ax.tick_params(labelsize=lab_size)\n",
    "    ax.set_xlabel(\"Time Window\", fontsize=font_size)\n",
    "    ax.set_ylabel(\"Variance\", fontsize=font_size)\n",
    "    plt.xticks(rotation=45)\n",
    "    sns.set(font_scale=1)\n",
    "    sns.set(style='white')\n",
    "    sns.despine()\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/variance_boxplot_dpg_{dist_per_grid}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Collect all variances for the new plot\n",
    "    all_variances = np.concatenate([variance_data[tw] for tw in time_windows if len(variance_data[tw]) > 0])\n",
    "    if len(all_variances) > 1:\n",
    "        mean_var = np.mean(all_variances)\n",
    "        std_var = np.std(all_variances, ddof=1)\n",
    "        n = len(all_variances)\n",
    "        se = std_var / np.sqrt(n)\n",
    "        error = 1.96 * se  # 95% confidence interval error term\n",
    "    else:\n",
    "        mean_var = np.nan\n",
    "        error = np.nan\n",
    "\n",
    "    return (dist_per_grid, mean_var, error)\n",
    "\n",
    "# Parallel processing\n",
    "max_processors = multiprocessing.cpu_count() - 1\n",
    "combinations = dist_per_grid_list  # Simplified to list of scalars\n",
    "\n",
    "with multiprocessing.Pool(processes=max_processors) as pool:\n",
    "    results_list = pool.map(run_single_combination, combinations)\n",
    "\n",
    "# Create the new plot\n",
    "grid_sizes = [result[0] for result in results_list]\n",
    "mean_vars = [result[1] for result in results_list]\n",
    "errors = [result[2] for result in results_list]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(grid_sizes, mean_vars, yerr=errors, fmt='-o', capsize=5)\n",
    "plt.xlabel('Grid Size (km)', fontsize=15)\n",
    "plt.ylabel('Mean Variance', fontsize=15)\n",
    "plt.title('Mean Variance of Order Counts vs Grid Size with 95% Confidence Intervals', fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mean_variance_vs_grid_size.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Processing complete. All plots have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new plot\n",
    "grid_sizes = [result[0] for result in results_list]\n",
    "mean_vars = [result[1] for result in results_list]\n",
    "errors = [result[2] for result in results_list]\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "flg, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.tick_params(labelsize=15)\n",
    "plt.errorbar(grid_sizes, mean_vars, yerr=errors, fmt='-o', capsize=5)\n",
    "plt.xlabel('Grid Size (km)', fontsize=15)\n",
    "plt.ylabel('Mean Variance', fontsize=15)\n",
    "plt.title('Mean Variance of Order Counts vs Grid Size with 95% Confidence Intervals', fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mean_variance_vs_grid_size.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalization for orders per grid cell each day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing grid size: 0.1 kmProcessing grid size: 0.6 kmProcessing grid size: 0.2 kmProcessing grid size: 0.3 kmProcessing grid size: 0.4 kmProcessing grid size: 0.5 kmProcessing grid size: 1.8 kmProcessing grid size: 2.3 km\n",
      "Processing grid size: 0.7 kmProcessing grid size: 0.8 kmProcessing grid size: 0.9 kmProcessing grid size: 2.0 kmProcessing grid size: 1.0 km\n",
      "\n",
      "\n",
      "\n",
      "Processing grid size: 1.3 km\n",
      "Processing grid size: 3.8 kmProcessing grid size: 3.3 km\n",
      "Processing grid size: 1.5 kmProcessing grid size: 4.3 kmProcessing grid size: 2.5 kmProcessing grid size: 4.8 kmProcessing grid size: 2.8 km\n",
      "Processing grid size: 5.0 kmProcessing grid size: 3.5 km\n",
      "\n",
      "\n",
      "\n",
      "Processing grid size: 3.0 km\n",
      "Processing grid size: 4.0 kmProcessing grid size: 4.5 km\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing complete. All plots have been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import multiprocessing\n",
    "# from Preprocessor import Preprocessor  # Assuming this is defined elsewhere\n",
    "\n",
    "# Load the data\n",
    "data_path = '/home/go3/wch_code/jx/real_data/data/cleaned_data2.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Define the dates\n",
    "all_dates = ['2022-10-17', '2022-10-18', '2022-10-19', '2022-10-20', '2022-10-21']\n",
    "all_dates = [pd.to_datetime(date).date() for date in all_dates]\n",
    "\n",
    "# Preprocess the data\n",
    "df = Preprocessor.preprocess(df, all_dates)\n",
    "\n",
    "# Define time windows (hourly from 08:00 to 23:59)\n",
    "time_windows = [\n",
    "    ('08:00', '09:59:59'), \n",
    "    ('10:00', '11:59:59'), \n",
    "    ('12:00', '13:59:59'),\n",
    "    ('14:00', '15:59:59'), \n",
    "    ('16:00', '17:59:59'), \n",
    "    ('18:00', '19:59:59'),\n",
    "    ('20:00', '21:59:59'), \n",
    "    ('22:00', '23:59:59')\n",
    "]\n",
    "\n",
    "# Define grid sizes in kilometers\n",
    "dist_per_grid_list = [\n",
    "    0.1, 0.2, 0.3, 0.4, 0.5, \n",
    "    0.6, 0.7, 0.8, 0.9, 1.0, \n",
    "    1.3, 1.5, 1.8,\n",
    "    2.0, 2.3, 2.5, 2.8, \n",
    "    3.0, 3.3, 3.5, 3.8, \n",
    "    4.0, 4.3, 4.5, 4.8, 5.0\n",
    "]\n",
    "\n",
    "def run_single_combination(dist_per_grid):\n",
    "    # Print the current grid size being processed\n",
    "    print(f\"Processing grid size: {dist_per_grid} km\")\n",
    "    \n",
    "    # Assign grid indices based on sender location\n",
    "    base_df, num_total_cells, _, _, _, _, _ = Preprocessor.cut_df(df, dist_per_grid, timeperiod=60)\n",
    "    \n",
    "    # Dictionary to store variances for each time window\n",
    "    variance_data = {}\n",
    "    mean_var = {}\n",
    "    # Process each time window\n",
    "    for tw in time_windows:\n",
    "        start_time = pd.to_datetime(tw[0]).time()\n",
    "        end_time = pd.to_datetime(tw[1]).time()\n",
    "        \n",
    "        # Filter orders within the time window\n",
    "        tw_df = base_df[(base_df['time'] >= start_time) & (base_df['time'] <= end_time)]\n",
    "        \n",
    "        # Count orders per grid cell per day\n",
    "        counts = tw_df.groupby(['sell_index', 'date']).size().reset_index(name='count')\n",
    "\n",
    "        # normalize the counts to avoid large variances due to high order counts\n",
    "        counts['count'] = (counts['count'] - counts['count'].mean()) / counts['count'].std()\n",
    "        \n",
    "        # Calculate variance of order counts across days for each grid cell\n",
    "        variances = counts.groupby('sell_index')['count'].var().reset_index(name='variance')\n",
    "        \n",
    "        # Store variances, excluding NaN\n",
    "        variance_data[tw] = variances['variance'].dropna().values\n",
    "\n",
    "        # Remove outliers\n",
    "        if len(variance_data[tw]) > 0:\n",
    "            q1 = np.percentile(variance_data[tw], 25)\n",
    "            q3 = np.percentile(variance_data[tw], 75)\n",
    "            q95 = np.percentile(variance_data[tw], 95)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            upper_bound = min(upper_bound, q95)\n",
    "            variance_data[tw] = variance_data[tw][(variance_data[tw] <= upper_bound)]\n",
    "\n",
    "        mean_var[tw] = variances['variance'].mean()\n",
    "\n",
    "    # Prepare data for boxplot\n",
    "    plot_data = []\n",
    "    for tw in time_windows:\n",
    "        variances = variance_data[tw]\n",
    "        for var in variances:\n",
    "            plot_data.append({'time_window': f\"{tw[0]}-{tw[1]}\", 'variance': var})\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "    save_path = 'var_boxplot/normalized'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Create and save the boxplot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    lab_size = 15\n",
    "    font_size = 15\n",
    "    sns.boxplot(x='time_window', y='variance', data=plot_df)\n",
    "    for idx, tw in enumerate(time_windows):\n",
    "        mean_val = mean_var[tw]\n",
    "        if not np.isnan(mean_val):\n",
    "            plt.plot(idx, mean_val, 'rD', markersize=8, label='Mean' if idx == 0 else '')\n",
    "    plt.title(f'Variance of Order Counts Across Days for Grid Size {dist_per_grid} km', fontsize=15)\n",
    "    ax.tick_params(labelsize=lab_size)\n",
    "    ax.set_xlabel(\"Time Window\", fontsize=font_size)\n",
    "    ax.set_ylabel(\"Variance\", fontsize=font_size)\n",
    "    plt.xticks(rotation=45)\n",
    "    sns.set(font_scale=1)\n",
    "    sns.set(style='white')\n",
    "    sns.despine()\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_path}/variance_boxplot_dpg_{dist_per_grid}.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Collect all variances for the new plot\n",
    "    all_variances = np.concatenate([variance_data[tw] for tw in time_windows if len(variance_data[tw]) > 0])\n",
    "    if len(all_variances) > 1:\n",
    "        mean_var = np.mean(all_variances)\n",
    "        std_var = np.std(all_variances, ddof=1)\n",
    "        n = len(all_variances)\n",
    "        se = std_var / np.sqrt(n)\n",
    "        error = 1.96 * se  # 95% confidence interval error term\n",
    "    else:\n",
    "        mean_var = np.nan\n",
    "        error = np.nan\n",
    "\n",
    "    return (dist_per_grid, mean_var, error)\n",
    "\n",
    "# Parallel processing\n",
    "max_processors = multiprocessing.cpu_count() - 1\n",
    "combinations = dist_per_grid_list  # Simplified to list of scalars\n",
    "\n",
    "with multiprocessing.Pool(processes=max_processors) as pool:\n",
    "    results_list = pool.map(run_single_combination, combinations)\n",
    "\n",
    "# Create the new plot\n",
    "grid_sizes = [result[0] for result in results_list]\n",
    "mean_vars = [result[1] for result in results_list]\n",
    "errors = [result[2] for result in results_list]\n",
    "\n",
    "save_path = 'var_boxplot/normalized'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(grid_sizes, mean_vars, yerr=errors, fmt='-o', capsize=5)\n",
    "plt.xlabel('Grid Size (km)', fontsize=15)\n",
    "plt.ylabel('Mean Variance', fontsize=15)\n",
    "plt.title('Mean Variance of Order Counts vs Grid Size with 95% Confidence Intervals', fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_path}mean_variance_vs_grid_size.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Processing complete. All plots have been saved.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
